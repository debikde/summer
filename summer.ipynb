{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-28T11:30:21.492953Z",
     "start_time": "2025-05-28T11:30:21.484069Z"
    }
   },
   "source": [
    "#TASK 1\n",
    "\n",
    "import re\n",
    "from collections import Counter\n",
    "file = open('task1text.txt', 'r', encoding='utf-8')\n",
    "data = file.read()\n",
    "\n",
    "data = re.sub(r'[^а-яА-ЯёЁ\\d\\s\\.\\,]', '', data)\n",
    "\n",
    "trash = set()\n",
    "data = data.split()\n",
    "\n",
    "counter = Counter(data)\n",
    "\n",
    "for i in counter:\n",
    "    if counter[i] > 10:\n",
    "        trash.add(i)\n",
    "\n",
    "clear = []\n",
    "for i in data:\n",
    "    if i not in trash:\n",
    "        clear.append(i)\n",
    "data = ' '.join(clear)\n",
    "print(data)\n",
    "print('\\nИз контекста мне не понятно является ли слово плод очепяткой или так задуманно. На всякий точечно заменю на плот\\n')\n",
    "newdata = data.replace(\"плод\", \"плот\")\n",
    "print(newdata)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тот, кто построил плод на летней школе в 2023 году, участвовал в покушении на господина. Имена преступников я не могу вам сообщить, но у вас есть возможность поехать на летнюю школу чтобы выяснить что там произошло и собрать информацию на месте. Прошу найдите виновных в покушении. Это необходимо для сохранения чести летней школы.\n",
      "\n",
      "Из контекста мне не понятно является ли слово плод очепяткой или так задуманно. На всякий точечно заменю на плот\n",
      "\n",
      "Тот, кто построил плот на летней школе в 2023 году, участвовал в покушении на господина. Имена преступников я не могу вам сообщить, но у вас есть возможность поехать на летнюю школу чтобы выяснить что там произошло и собрать информацию на месте. Прошу найдите виновных в покушении. Это необходимо для сохранения чести летней школы.\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "1f19243115afa451"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-31T11:00:16.783072Z",
     "start_time": "2025-05-31T11:00:14.747991Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#TASK 5\n",
    "import pandas as pd\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "from collections import Counter\n",
    "df = pd.read_csv(\"sample.tsv\", sep=\"\\t\", header=None, names=[\"label\", \"message\"])\n",
    "stopwords = pd.read_csv(\"english.csv\", header=None)\n",
    "stop_words = set(stopwords[0].str.strip().tolist())\n",
    "\n",
    "df[\"message\"] = df[\"message\"].str.lower().apply(lambda x: re.sub(r'[^a-z\\s]', '', x))\n",
    "df[\"message\"] = df[\"message\"].apply(lambda x: word_tokenize(x))\n",
    "print('\\nПриведено все к нижнему регистру, удалены символы не являющеся буквами и пробелами.\\n')\n",
    "print(df.message)\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "df[\"message\"] = df[\"message\"].apply(lambda tokens: [lemmatizer.lemmatize(word) for word in tokens])\n",
    "print('\\nЛемматизация\\n')\n",
    "print(df.message)\n",
    "\n",
    "\n",
    "df[\"message\"] = df[\"message\"].apply(lambda tokens: [word for word in tokens if word not in stop_words])\n",
    "print('\\nУдаление стоп слов\\n')\n",
    "print(df.message)\n",
    "\n",
    "\n",
    "\n",
    "all_ham_words = [word for message in df[df['label'] == \"ham\"][\"message\"] for word in message]\n",
    "all_spam_words = [word for message in df[df['label'] == \"spam\"][\"message\"] for word in message]\n",
    "counterHam = Counter(all_ham_words)\n",
    "counterSpam = Counter(all_spam_words)\n",
    "longCounterHam = [(word, count) for word, count in counterHam.items() if len(word) >= 3]\n",
    "longCounterSpam = [(word, count) for word, count in counterSpam.items() if len(word) >= 3]\n",
    "print(\"\\nКоличество встречающихся 10 слов длиннее 3х\\n\")\n",
    "sortHum = sorted(longCounterHam, key=lambda x: x[1], reverse=True)\n",
    "sortSpam = sorted(longCounterSpam, key=lambda x: x[1], reverse=True)\n",
    "print(f'Не спам сообщения{sortHum[:10]}')\n",
    "print(f'Спам сообщения{sortSpam[:10]}')\n",
    "\n",
    "all_words = [word for message in df[\"message\"] for word in message]\n",
    "counter_all = Counter(all_words)\n",
    "\n",
    "filtered_vocab = sorted([word for word, count in counter_all.items() if len(word) >= 3 and count >= 10])\n",
    "\n",
    "print(\"\\nКоличество уникальных слов длиной более 3 и частотой более 10:\")\n",
    "print(len(filtered_vocab))\n",
    "print(filtered_vocab[:10]) \n",
    "\n",
    "\n",
    "def vectorize(tokens, vocab):\n",
    "    word_counts = Counter(tokens)\n",
    "    return [word_counts[word] for word in vocab]\n",
    "\n",
    "\n",
    "vectors = df[\"message\"].apply(lambda tokens: vectorize(tokens, filtered_vocab)).tolist()\n",
    "vector_df = pd.DataFrame(vectors, columns=filtered_vocab)\n",
    "\n",
    "print(vector_df.head())\n",
    "nonzero_rows = vector_df[(vector_df != 0).any(axis=1)]\n"
   ],
   "id": "6ddf5802dece0e3a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Приведено все к нижнему регистру, удалены символы не являющеся буквами и пробелами.\n",
      "\n",
      "0       [have, your, lunch, and, come, quickly, and, o...\n",
      "1       [join, the, uks, horniest, dogging, service, a...\n",
      "2       [you, are, chosen, to, receive, a, award, pls,...\n",
      "3       [alright, tylers, got, a, minor, crisis, and, ...\n",
      "4       [sad, story, of, a, man, last, week, was, my, ...\n",
      "                              ...                        \n",
      "3710    [hello, which, the, site, to, download, songs,...\n",
      "3711    [my, planning, usually, stops, at, find, hella...\n",
      "3712              [are, u, awake, is, there, snow, there]\n",
      "3713                            [sorry, ill, call, later]\n",
      "3714                       [you, can, never, do, nothing]\n",
      "Name: message, Length: 3715, dtype: object\n",
      "\n",
      "Лемматизация\n",
      "\n",
      "0       [have, your, lunch, and, come, quickly, and, o...\n",
      "1       [join, the, uk, horniest, dogging, service, an...\n",
      "2       [you, are, chosen, to, receive, a, award, pls,...\n",
      "3       [alright, tyler, got, a, minor, crisis, and, h...\n",
      "4       [sad, story, of, a, man, last, week, wa, my, b...\n",
      "                              ...                        \n",
      "3710    [hello, which, the, site, to, download, song, ...\n",
      "3711    [my, planning, usually, stop, at, find, hella,...\n",
      "3712              [are, u, awake, is, there, snow, there]\n",
      "3713                            [sorry, ill, call, later]\n",
      "3714                       [you, can, never, do, nothing]\n",
      "Name: message, Length: 3715, dtype: object\n",
      "\n",
      "Удаление стоп слов\n",
      "\n",
      "0                      [lunch, come, quickly, open, door]\n",
      "1       [join, uk, horniest, dogging, service, u, sex,...\n",
      "2       [chosen, receive, award, pls, call, claim, num...\n",
      "3       [alright, tyler, got, minor, crisis, ha, home,...\n",
      "4       [sad, story, man, last, week, wa, bday, wife, ...\n",
      "                              ...                        \n",
      "3710           [hello, site, download, song, urgent, pls]\n",
      "3711    [planning, usually, stop, find, hella, weed, s...\n",
      "3712                                     [u, awake, snow]\n",
      "3713                            [sorry, ill, call, later]\n",
      "3714                                     [never, nothing]\n",
      "Name: message, Length: 3715, dtype: object\n",
      "\n",
      "Количество встречающихся 10 слов длиннее 3х\n",
      "\n",
      "Не спам сообщения[('get', 196), ('dont', 190), ('come', 168), ('like', 168), ('got', 166), ('know', 165), ('call', 162), ('ill', 162), ('ltgt', 161), ('good', 151)]\n",
      "Спам сообщения[('call', 244), ('free', 147), ('text', 94), ('mobile', 92), ('txt', 90), ('claim', 75), ('stop', 73), ('reply', 69), ('prize', 56), ('new', 54)]\n",
      "\n",
      "Количество уникальных слов длиной более 3 и частотой более 10:\n",
      "565\n",
      "['abiola', 'able', 'abt', 'account', 'actually', 'address', 'aft', 'afternoon', 'age', 'aight']\n",
      "0       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
      "1       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
      "2       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
      "3       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...\n",
      "4       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
      "                              ...                        \n",
      "3710    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
      "3711    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
      "3712    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
      "3713    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
      "3714    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
      "Name: fvector, Length: 3715, dtype: object\n",
      "   abiola  able  abt  account  actually  address  aft  afternoon  age  aight  \\\n",
      "0       0     0    0        0         0        0    0          0    0      0   \n",
      "1       0     0    0        0         0        0    0          0    0      0   \n",
      "2       0     0    0        0         0        0    0          0    0      0   \n",
      "3       0     0    0        0         0        0    0          0    0      0   \n",
      "4       0     0    0        0         0        0    0          0    0      0   \n",
      "\n",
      "   ...  xmas  xxx  yeah  year  yes  yesterday  yet  youll  youre  yup  \n",
      "0  ...     0    0     0     0    0          0    0      0      0    0  \n",
      "1  ...     0    0     0     0    0          0    0      0      0    0  \n",
      "2  ...     0    0     0     0    0          0    0      0      0    0  \n",
      "3  ...     0    0     0     0    0          0    0      0      0    0  \n",
      "4  ...     0    0     0     0    0          0    0      0      0    0  \n",
      "\n",
      "[5 rows x 565 columns]\n",
      "Количество сообщений с хотя бы одним значимым словом: 3552\n",
      "   abiola  able  abt  account  actually  address  aft  afternoon  age  aight  \\\n",
      "0       0     0    0        0         0        0    0          0    0      0   \n",
      "1       0     0    0        0         0        0    0          0    0      0   \n",
      "2       0     0    0        0         0        0    0          0    0      0   \n",
      "3       0     0    0        0         0        0    0          0    0      0   \n",
      "4       0     0    0        0         0        0    0          0    0      0   \n",
      "\n",
      "   ...  xmas  xxx  yeah  year  yes  yesterday  yet  youll  youre  yup  \n",
      "0  ...     0    0     0     0    0          0    0      0      0    0  \n",
      "1  ...     0    0     0     0    0          0    0      0      0    0  \n",
      "2  ...     0    0     0     0    0          0    0      0      0    0  \n",
      "3  ...     0    0     0     0    0          0    0      0      0    0  \n",
      "4  ...     0    0     0     0    0          0    0      0      0    0  \n",
      "\n",
      "[5 rows x 565 columns]\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Задание Spelling Bee.\n",
    "Для игры создан словарь английских слов (файл джейсон) с просчитанными очками для каждого слова для ускорения. Случайные слова стали супер словами, за которые будет выдано больше очков.\n",
    "Сама игра находится в файле sbellingBee.py, а запустить ее можно из main"
   ],
   "id": "38a4886adb822a7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "1c0d1fb1db7a9b4d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "import json\n",
    "import random\n",
    "\n",
    "def calculate_score(word):\n",
    "    length = len(word)\n",
    "    if length < 4:\n",
    "        return 0\n",
    "    elif length == 4:\n",
    "        return 1\n",
    "    elif 5 <= length <= 7:\n",
    "        return length\n",
    "    else:\n",
    "        return length * 2\n",
    "\n",
    "def assign_scores(word_dict):\n",
    "    new_dict = {}\n",
    "    for word in word_dict.keys():\n",
    "        score = calculate_score(word)\n",
    "        if score > 0:\n",
    "            new_dict[word.lower()] = score\n",
    "    return new_dict\n",
    "\n",
    "def add_super_words(word_score_dict, super_multiplier=2, super_ratio=0.02):\n",
    "    words = list(word_score_dict.keys())\n",
    "    super_words = random.sample(words, int(len(words) * super_ratio))\n",
    "\n",
    "    for word in super_words:\n",
    "        word_score_dict[word] *= super_multiplier\n",
    "    return word_score_dict\n",
    "\n",
    "with open(\"words_dictionary.json\", \"r\") as f:\n",
    "    original_dict = json.load(f)\n",
    "\n",
    "scored_words = assign_scores(original_dict)\n",
    "scored_with_supers = add_super_words(scored_words)\n",
    "\n",
    "with open(\"scored_words.json\", \"w\") as f:\n",
    "    json.dump(scored_with_supers, f, indent=2)"
   ],
   "id": "8cb7a31f5159c414"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
